{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train_inference_class0123.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"26UGd_DJ3ePU"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","\n","! pip install --upgrade albumentations\n","import albumentations as A\n","\n","from copy import copy\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import gc\n","import tqdm\n","from sklearn.model_selection import StratifiedKFold\n","import cv2\n","\n","import torch\n","torch.backends.cudnn.benchmark = True\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset, Subset\n","\n","!pip install catalyst\n","from catalyst import utils, dl, callbacks\n","SEED = 42\n","utils.set_global_seed(SEED)\n","utils.prepare_cudnn(deterministic=True)\n","\n","!pip install segmentation_models_pytorch\n","import segmentation_models_pytorch as smp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFoGpVFk4k1K","executionInfo":{"status":"ok","timestamp":1607640882438,"user_tz":-60,"elapsed":102251,"user":{"displayName":"Mengdi Song","photoUrl":"","userId":"07489826126733223260"}},"outputId":"18ce0612-4d6e-4ae3-9ece-5f7d81c4242b"},"source":["competition_path = \"/content/gdrive/My Drive/Seismic Facies Identification/\"\n","data_path = competition_path + \"data/\"\n","train_img = np.load(data_path+'data_train.npz', allow_pickle=True, mmap_mode='r')['data']\n","train_labels = np.load(data_path+'labels_train.npz', allow_pickle=True, mmap_mode='r')['labels']\n","test1_img = np.load(data_path+'data_test_1.npz', allow_pickle=True, mmap_mode='r')['data']\n","test2_img = np.load(data_path+'data_test_2.npz', allow_pickle=True, mmap_mode='r')['data']\n","train_labels -= 1\n","train_labels[:,0,:] = train_labels[:,1,:]\n","\n","pseudo_label = False\n","# add pseudo-label images\n","if pseudo_label:\n","  pseudo_pct = 0.5\n","  submission_file_test1 = competition_path + \"round 1 submissions/prediction20_DLV3Plus_resnext50_32x4d.npz\"\n","  #submission_file_test1 = competition_path + \"submissions/prediction_test1_h.npz\"\n","  submission_file_test2 = competition_path + \"submissions/prediction34_class5_CE_1_5.npz\"\n","  # add images from test1\n","  pred = np.load(submission_file_test1, mmap_mode='r')['prediction']\n","  pred -= 1\n","  pseudo_image_nb_h = int(test1_img.shape[2] * pseudo_pct)\n","  train_img = np.concatenate((train_img, test1_img[:,:,:pseudo_image_nb_h]), axis=2)\n","  train_labels = np.concatenate((train_labels, pred[:,:,:pseudo_image_nb_h]), axis=2)\n","  # add images from test2\n","  pred = np.load(submission_file_test2, mmap_mode='r')['prediction']\n","  pred -= 1\n","  pseudo_image_nb_h = train_img.shape[2]\n","  pseudo_image_nb_v = int(test2_img.shape[1] * pseudo_pct)\n","  train_img = np.concatenate((train_img, test2_img[:,:pseudo_image_nb_v,:pseudo_image_nb_h]), axis=1)\n","  train_labels = np.concatenate((train_labels, pred[:,:pseudo_image_nb_v,:pseudo_image_nb_h]), axis=1)\n","  print(train_img.shape)\n","\n","# merge labels for binary classification\n","binary_class = \"class_0123\" # \"class_4\", \"class_5\", \"class_0123\" or \"class_012345\"\n","if binary_class == \"class_012345\":\n","  classes = 6\n","  weights = [1, 1, 1, 1, 10, 1]\n","elif binary_class == \"class_0123\":\n","  classes = 4\n","  weights = [1, 5, 1, 10]\n","  train_labels[train_labels==4] = 1\n","  train_labels[train_labels==5] = 1\n","elif binary_class == \"class_4\":\n","  train_img = train_img[170:618, :, :448] # crop images\n","  train_labels = train_labels[170:618, :, :448] # crop images\n","  classes = 2\n","  train_labels[train_labels==1] = 0\n","  train_labels[train_labels==2] = 0\n","  train_labels[train_labels==3] = 0\n","  train_labels[train_labels==4] = 1\n","  train_labels[train_labels==5] = 0\n","elif binary_class == \"class_5\":\n","  train_img = train_img[92:636, :, :] # crop images\n","  train_labels = train_labels[92:636, :, :] # crop images\n","  classes = 2\n","  weights = [1, 5]\n","  train_labels[train_labels==1] = 0\n","  train_labels[train_labels==2] = 0\n","  train_labels[train_labels==3] = 0\n","  train_labels[train_labels==4] = 0\n","  train_labels[train_labels==5] = 1\n","\n","print(f\"train_img {train_img.shape} train_lables {train_labels.shape} test1_img {test1_img.shape} test2_img {test2_img.shape}\")\n","\n","\"\"\"\n","# normalize values to [0, 1]\n","_min = min(train_img.min(), test1_img.min(), test2_img.min())\n","_max = max(train_img.max(), test1_img.max(), test2_img.max())\n","train_img = (train_img - _min) / (_max - _min)\n","test1_img = (test1_img - _min) / (_max - _min)\n","test2_img = (test2_img - _min) / (_max - _min)\n","\"\"\"\n","# normalize values to max(abs())==1\n","_min = min(train_img.min(), test1_img.min(), test2_img.min())\n","_max = max(train_img.max(), test1_img.max(), test2_img.max())\n","divide = max(-_min, _max)\n","train_img = train_img / divide\n","test1_img = test1_img / divide\n","test2_img = test2_img / divide\n","\n","def calculate_weights(train_labels):\n","  labels = [0, 1, 2, 3, 4, 5]\n","  weights = []\n","  for label in labels:\n","    weights.append(train_labels.size / np.sum(train_labels==label) / len(labels))\n","  return weights\n","\n","#weights = calculate_weights(train_labels)\n","#print(weights)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_img (1006, 782, 590) train_lables (1006, 782, 590) test1_img (1006, 782, 251) test2_img (1006, 334, 841)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBzqMiLlX8l5"},"source":["def train_transform(image, mask):\n","  if binary_class == \"class_012345\" or binary_class == \"class_0123\":\n","    height = 896\n","    width = 256\n","  elif binary_class == \"class_4\":\n","    height = 448\n","    width = 448\n","  elif binary_class == \"class_5\":\n","    height = 544\n","    width = 256\n","  return A.Compose([   \n","    A.ShiftScaleRotate(p=0.7, shift_limit=0, scale_limit=0.15, rotate_limit=25),\n","    #A.Rotate(p=0.8, limit=25, interpolation=cv2.INTER_LINEAR), # cv2.INTER_LINEAR or cv2.INTER_NEAREST\n","    #A.OneOf([\n","    #     A.ShiftScaleRotate(p=0.8, shift_limit=0, scale_limit=0.15, rotate_limit=25),\n","    #     A.IAAPiecewiseAffine(p=0.8, scale=(0.03, 0.12), nb_rows=4, nb_cols=4),\n","    #], p=1),\n","    A.RandomCrop(p=1, height=height, width=width),\n","    A.MultiplicativeNoise(p=0.7, multiplier=(0.8, 1.2), per_channel=False, elementwise=False),\n","    #A.GaussNoise(p=0.8, var_limit=(10.0, 50.0)), # var_limit to be optimized\n","    A.HorizontalFlip(p=0.5),\n","  ])(image=image, mask=mask)\n","\n","def valid_transform(image, mask):\n","  if binary_class == \"class_012345\" or binary_class == \"class_0123\":\n","    height = 1024\n","    width = 800\n","  elif binary_class == \"class_4\":\n","    height = 448\n","    width = 448\n","  elif binary_class == \"class_5\":\n","    height = 544\n","    width = 800\n","  return A.Compose([\n","    A.PadIfNeeded(p=1, min_height=height, min_width=width), # border_mode=4 reflect_101 \n","  ])(image=image, mask=mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9F6x-l3CdHX"},"source":["class SeismicFaciesDataset(Dataset):\n","  def __init__(self, img, labels, train=True, both_axis=True, channels=3):\n","    self.img = img\n","    self.labels = labels\n","    self.train = train\n","    self.both_axis = both_axis\n","    self.channels = channels\n","    self.side_channels = int((channels - 1) / 2)\n","    self.xaxis = self.img.shape[1]\n","    self.yaxis = self.img.shape[2]\n","    self.ximages = self.xaxis - self.side_channels * 2\n","    self.yimages = self.yaxis - self.side_channels * 2\n","\n","  def __len__(self):\n","    if self.both_axis:\n","      return self.ximages + self.yimages\n","    else:\n","      return self.yimages\n","\n","  def __getitem__(self, idx):\n","    if idx < self.yimages:\n","      image, mask = self.img[:, :, idx:idx+self.channels], self.labels[:, :, idx+self.side_channels]\n","    else:\n","      idx = idx - self.yimages\n","      image, mask = self.img[:, idx:idx+self.channels], self.labels[:, idx+self.side_channels]\n","      image = np.moveaxis(image, 1, 2)\n","\n","    if self.train:\n","      augmented = train_transform(image, mask)\n","    else:\n","      augmented = valid_transform(image, mask)\n","    image, mask = augmented['image'], augmented['mask']\n","        \n","    return [np.moveaxis(image, 2, 0), np.expand_dims(mask, 0)]\n","\n","\n","class SeismicFaciesTestset(Dataset):\n","  def __init__(self, img, batch_axis=2, channels=3): # batch_axis = 1 (x_axis) or 2 (y_axis)\n","    self.img = img\n","    self.batch_axis = batch_axis\n","    self.channels = channels\n","    self.side_channels = int((channels - 1) / 2)\n","    self.image_nb = self.img.shape[self.batch_axis]\n","\n","  def __len__(self):\n","    return self.image_nb\n","\n","  def __getitem__(self, idx):\n","    if idx < self.side_channels:\n","      idx = self.side_channels\n","    \n","    if idx > self.image_nb-self.side_channels-1:\n","      idx = self.image_nb-self.side_channels-1\n","    if self.batch_axis == 2:\n","      image = self.img[:, :, idx-self.side_channels:idx+self.side_channels+1]\n","    else:\n","      image = self.img[:, idx-self.side_channels:idx+self.side_channels+1, :]\n","      image = np.moveaxis(image, 1, 2)\n","\n","    #image = A.PadIfNeeded(p=1, min_height=1024, min_width=800)(image=image)[\"image\"]\n","    bboxes = [[0, 0, image.shape[1], image.shape[0], \"original_image\"]] # width and then height\n","    augmented = A.Compose([\n","          A.PadIfNeeded(p=1, min_height=1024, min_width=1024),\n","          ], bbox_params=A.BboxParams(format='coco'))(image=image, bboxes=bboxes)\n","    image, self.bboxes = augmented[\"image\"], augmented[\"bboxes\"]\n","    return [np.moveaxis(image, 2, 0)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TfI21QxGqPlf"},"source":["class GDiceLoss(torch.nn.Module):\n","    def __init__(self, apply_nonlin=None, smooth=1e-5):\n","        \"\"\"\n","        Generalized Dice;\n","        Copy from: https://github.com/LIVIAETS/surface-loss/blob/108bd9892adca476e6cdf424124bc6268707498e/losses.py#L29\n","        paper: https://arxiv.org/pdf/1707.03237.pdf\n","        tf code: https://github.com/NifTK/NiftyNet/blob/dev/niftynet/layer/loss_segmentation.py#L279\n","        \"\"\"\n","        super(GDiceLoss, self).__init__()\n","\n","        self.apply_nonlin = apply_nonlin\n","        self.smooth = smooth\n","\n","    def forward(self, net_output, gt):\n","        shp_x = net_output.shape # (batch size,class_num,x,y,z)\n","        shp_y = gt.shape # (batch size,1,x,y,z)\n","        # one hot code for gt\n","        with torch.no_grad():\n","            if len(shp_x) != len(shp_y):\n","                gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n","\n","            if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n","                # if this is the case then gt is probably already a one hot encoding\n","                y_onehot = gt\n","            else:\n","                gt = gt.long()\n","                y_onehot = torch.zeros(shp_x)\n","                if net_output.device.type == \"cuda\":\n","                    y_onehot = y_onehot.cuda(net_output.device.index)\n","                y_onehot.scatter_(1, gt, 1)\n","\n","\n","        if self.apply_nonlin is not None:\n","            net_output = self.apply_nonlin(net_output)\n","    \n","        # copy from https://github.com/LIVIAETS/surface-loss/blob/108bd9892adca476e6cdf424124bc6268707498e/losses.py#L29\n","        w: torch.Tensor = 1 / (torch.einsum(\"bcxy->bc\", y_onehot).type(torch.float32) + 1e-10)**2\n","        intersection: torch.Tensor = w * torch.einsum(\"bcxy, bcxy->bc\", net_output, y_onehot)\n","        union: torch.Tensor = w * (torch.einsum(\"bcxy->bc\", net_output) + torch.einsum(\"bcxy->bc\", y_onehot))\n","        divided: torch.Tensor =  - 2 * (torch.einsum(\"bc->b\", intersection) + self.smooth) / (torch.einsum(\"bc->b\", union) + self.smooth)\n","        gdc = divided.mean()\n","\n","        return gdc\n","\n","\n","def flatten(tensor):\n","    \"\"\"Flattens a given tensor such that the channel axis is first.\n","    The shapes are transformed as follows:\n","       (N, C, D, H, W) -> (C, N * D * H * W)\n","    \"\"\"\n","    C = tensor.size(1)\n","    # new axis order\n","    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n","    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n","    transposed = tensor.permute(axis_order).contiguous()\n","    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n","    return transposed.view(C, -1)\n","\n","class GDiceLossV2(torch.nn.Module):\n","    def __init__(self, apply_nonlin=None, smooth=1e-5):\n","        \"\"\"\n","        Generalized Dice;\n","        Copy from: https://github.com/wolny/pytorch-3dunet/blob/6e5a24b6438f8c631289c10638a17dea14d42051/unet3d/losses.py#L75\n","        paper: https://arxiv.org/pdf/1707.03237.pdf\n","        tf code: https://github.com/NifTK/NiftyNet/blob/dev/niftynet/layer/loss_segmentation.py#L279\n","        \"\"\"\n","        super(GDiceLossV2, self).__init__()\n","\n","        self.apply_nonlin = apply_nonlin\n","        self.smooth = smooth\n","\n","    def forward(self, net_output, gt):\n","        shp_x = net_output.shape # (batch size,class_num,x,y,z)\n","        shp_y = gt.shape # (batch size,1,x,y,z)\n","        # one hot code for gt\n","        with torch.no_grad():\n","            if len(shp_x) != len(shp_y):\n","                gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n","\n","            if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n","                # if this is the case then gt is probably already a one hot encoding\n","                y_onehot = gt\n","            else:\n","                gt = gt.long()\n","                y_onehot = torch.zeros(shp_x)\n","                if net_output.device.type == \"cuda\":\n","                    y_onehot = y_onehot.cuda(net_output.device.index)\n","                y_onehot.scatter_(1, gt, 1)\n","\n","\n","        if self.apply_nonlin is not None:\n","            net_output = self.apply_nonlin(net_output)\n","\n","        input = flatten(net_output)\n","        target = flatten(y_onehot)\n","        target = target.float()\n","        target_sum = target.sum(-1)\n","        #weights_base = [1.539948, 0.4490113, 6.48968674, 0.50709277, 11.38007304, 1.09947775]\n","          # weights_base is calculated by : np.array(calculate_weights(train_labels[:,-50:,:]))\n","        weights = [1.539948, 0.4490113, 6.48968674, 0.50709277] # (for class0123)\n","        #weights = [1.539948, 0.4490113, 6.48968674, 0.50709277, 113.8007304, 1.09947775] # weights_base*[1,1,1,1,10,1] (for class4)\n","        #weights = [1.539948, 0.4490113, 6.48968674, 0.50709277, 11.38007304, 5.49738875] # weights_base**[1,1,1,1,1,5] (for class5)\n","        class_weights = torch.tensor(weights).cuda(net_output.device.index)\n","\n","        intersect = (input * target).sum(-1) * class_weights\n","        intersect = intersect.sum()\n","\n","        denominator = ((input + target).sum(-1) * class_weights).sum()\n","\n","        return  - 2. * intersect / denominator.clamp(min=self.smooth)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzvxPwgSvSkq"},"source":["import catalyst\n","import sklearn\n","\n","# catalyst pipeline\n","channels = 1\n","batch_size = 8\n","valid_batch_size = 4\n","\n","class CustomRunner(dl.Runner):\n","\n","  def predict_batch(self, batch):\n","      # model inference step\n","      return self.model(batch[0].to(self.device))\n","\n","  def _handle_batch(self, batch):\n","      # model train/valid step\n","      x, y = batch\n","      y_hat = self.model(x)\n","      \n","      loss = self.criterion[\"CE\"](y_hat, torch.squeeze(y.long()))*0.3 + self.criterion[\"GDice\"](y_hat, torch.squeeze(y.long()))*0.7\n","      y_hat_reshaped = y_hat.permute(0, 2, 3, 1).reshape(-1, classes)\n","      y_reshaped = y.permute(0, 2, 3, 1).reshape(-1, 1)\n","      #f1_score = sklearn.metrics.f1_score(y_reshaped.cpu().detach().numpy(), y_hat_reshaped.cpu().detach().numpy().argmax(axis=1), average='macro')\n","      #accuracy01, accuracy02 = catalyst.metrics.accuracy(y_hat_reshaped, y_reshaped, topk=(1, 2))\n","      [accuracy01] = catalyst.metrics.accuracy(y_hat_reshaped, y_reshaped)\n","      f1_score = catalyst.metrics.f1_score(torch.argmax(y_hat_reshaped, dim=1, keepdims=True), y_reshaped, num_classes=classes)\n","\n","      self.batch_metrics.update(\n","          {\"loss\": loss, \"accuracy_01\": accuracy01, \"f1_score\": torch.mean(f1_score)} # \"accuracy_2\": accuracy02, \"f1_score\": f1_score\n","      )\n","\n","      if self.is_train_loader:\n","          loss.backward()\n","          self.optimizer.step()\n","          self.optimizer.zero_grad()\n","\n","#model = smp.Unet(encoder_name=\"efficientnet-b3\", in_channels=channels, classes=classes, activation=\"softmax\", decoder_attention_type=\"scse\", encoder_weights='imagenet')\n","model = smp.DeepLabV3Plus(encoder_name=\"efficientnet-b3\", in_channels=channels, classes=classes, activation=\"softmax\", encoder_weights='imagenet')\n","#model = smp.DeepLabV3Plus(encoder_name=\"resnext50_32x4d\", in_channels=channels, classes=classes, activation=\"softmax\", encoder_weights='imagenet')\n","#model = smp.DeepLabV3Plus(encoder_name=\"se_resnext101_32x4d\", in_channels=channels, classes=classes, activation=\"softmax\", encoder_weights='imagenet')\n","#model = smp.DeepLabV3Plus(encoder_name=\"inception_resnet_v2\", in_channels=channels, classes=classes, activation=\"softmax\", encoder_weights='imagenet')\n","#model = smp.Unet(encoder_name=\"efficientnet-b3\", in_channels=channels, classes=classes, activation=\"softmax\", decoder_attention_type=\"scse\", encoder_weights='imagenet')\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","#criterion = catalyst.contrib.nn.LovaszLossMultiClass()\n","criterion_CE = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(weights).cuda())\n","criterion_GDice = GDiceLossV2()\n","#criterion = catalyst.contrib.nn.DiceLoss(activation=None)\n","#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience=2)\n","es_callback = callbacks.early_stop.EarlyStoppingCallback(patience=5, metric='loss', minimize=True, min_delta=1e-6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"veoH4wujyCkk"},"source":["# train\n","valid_ratio = 0.1\n","\n","dataset = SeismicFaciesDataset(train_img, train_labels, channels=channels)\n","nb_valid_xaxis = int(dataset.xaxis * valid_ratio)\n","nb_valid_yaxis = int(dataset.yaxis * valid_ratio)\n","# split\n","#train_index = list(range(nb_valid_yaxis, dataset.yaxis)) + list(range(dataset.yaxis + nb_valid_xaxis, dataset.__len__()))\n","#valid_index = list(range(0, nb_valid_yaxis)) + list(range(dataset.yaxis, dataset.yaxis + nb_valid_xaxis))\n","# split (train set = whole data; valid set = near to test set)\n","train_index = list(range(0, dataset.__len__()))\n","valid_index = list(range(dataset.__len__() - nb_valid_xaxis, dataset.__len__()))\n","\n","train_dataset, valid_dataset = Subset(dataset, train_index), Subset(copy(dataset), valid_index)\n","valid_dataset.dataset.train = False\n","\n","loaders = {\n","  \"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True, drop_last=True),\n","  \"valid\": DataLoader(valid_dataset, batch_size=valid_batch_size, num_workers=0, shuffle=False, drop_last=False),\n","}\n","\n","#checkpoint = utils.load_checkpoint(f'{competition_path}/logs/checkpoints/best_class0123_01.pth')\n","#utils.unpack_checkpoint(checkpoint, model=model)\n","runner = CustomRunner()\n","# model training\n","runner.train(\n","  model=model,\n","  optimizer=optimizer,\n","  criterion={\"CE\": criterion_CE, \"GDice\": criterion_GDice}, \n","  #scheduler=scheduler,\n","  loaders=loaders,\n","  logdir=competition_path+\"logs/\",\n","  callbacks=[es_callback],\n","  num_epochs=20,\n","  verbose=True,\n","  load_best_on_end=True,\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tmqYtY9R6v-G"},"source":["def inference(img, batch_axis=1):\n","  predict_from_checkpoint = True\n","  TTA = False\n","\n","  testset = SeismicFaciesTestset(img, batch_axis=batch_axis, channels=channels)\n","  testloader = DataLoader(testset, batch_size=1, num_workers=0, shuffle=False)\n","\n","  if predict_from_checkpoint:\n","    checkpoint = utils.load_checkpoint(f'{competition_path}/logs/checkpoints/best_class0123_02.pth')\n","    utils.unpack_checkpoint(checkpoint, model=model)\n","    runner = CustomRunner(model=model)\n","    print(\"Checkpoint loaded.\")\n","\n","  if TTA:\n","    !pip install ttach\n","    import ttach as tta\n","    transforms = tta.Compose([\n","          tta.HorizontalFlip(),\n","          #tta.Multiply([0.95, 1, 1.05]),\n","          #tta.Add([-0.05, 0, 0.05]),\n","          #tta.Scale([1, 2]),\n","      ])\n","    tta_model = tta.SegmentationTTAWrapper(model, transforms)\n","    runner = CustomRunner(model=tta_model)\n","    \n","  pred = []\n","  for pred_batch in tqdm.tqdm(runner.predict_loader(loader=testloader)):\n","    bboxes = testloader.dataset.bboxes[0]\n","    pred_batch_np = pred_batch.cpu().numpy().argmax(axis=1)\n","    pred_batch_np = pred_batch_np[:, int(bboxes[1]):int(bboxes[1]+bboxes[3]), int(bboxes[0]):int(bboxes[0]+bboxes[2])]\n","    pred.append(pred_batch_np.copy())\n","  pred = np.concatenate(pred, axis=0)\n","  if batch_axis==1:\n","    pred = pred.transpose((1, 0, 2))\n","  else:\n","    pred = pred.transpose((1, 2, 0))\n","\n","  return pred\n","\n","del train_img, test1_img\n","gc.collect()\n","#pred1 = inference(test1_img, batch_axis=2)\n","pred2 = inference(test2_img, batch_axis=1) # vertical images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"impcX8uFJ5QM"},"source":["from google.colab import files\n","\n","def download_submission(pred, submission_file):\n","  np.savez_compressed(\n","      submission_file,\n","      prediction=pred.astype(train_labels.dtype) + 1\n","  )\n","  files.download(submission_file)\n","\n","# submission for testset 1\n","submission_file = competition_path+'submissions/prediction_test1.npz'\n","#download_submission(pred1, submission_file)\n","# submission for testset 2\n","submission_file = competition_path+'binary_predictions/class0123_02_best.npz'\n","download_submission(pred2, submission_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9esoIPK7YHxD"},"source":["# plot image & predictions\n","def plot_image_pred(image, pred=None, labels=None):\n","\n","  # plot image & labels\n","  fig, ax = plt.subplots(1,3, sharey=True)\n","  fig.set_size_inches(20, 8)\n","  fig.suptitle(\"2D slice of the 3D seismic data volume\", fontsize=20)\n","  ax[0].imshow(image, cmap='terrain')\n","  ax[0].set_xlabel('X or Y Axis', fontsize=14)\n","  ax[0].set_ylabel('Z Axis: Top - Bottom', fontsize=14)\n","  ax[0].set_title(\"image\", fontsize=20)\n","  if labels is not None:\n","    print(np.unique(labels))\n","    ax[1].imshow(labels)\n","    ax[1].set_xlabel('X or Y Axis', fontsize=14)\n","    ax[1].set_title(\"labels\", fontsize=20)\n","    ax[2].imshow(image, cmap='terrain')\n","    ax[2].imshow(labels, alpha=0.4, cmap='twilight')\n","    ax[2].set_xlabel('X or Y Axis', fontsize=14)\n","    ax[2].set_title(\"image + labels\", fontsize=20)\n","\n","  # plot pred & labels\n","  if pred is not None:\n","    fig, ax = plt.subplots(1,3, sharey=True)\n","    fig.set_size_inches(20, 8)\n","    fig.suptitle(\"Predictions & labels\", fontsize=20)\n","    ax[0].imshow(pred)\n","    ax[0].set_xlabel('X or Y Axis', fontsize=14)\n","    ax[0].set_title(\"predictions\", fontsize=20)\n","    if labels is not None:\n","      ax[1].imshow(labels)\n","      ax[1].set_xlabel('X or Y Axis', fontsize=14)\n","      ax[1].set_title(\"labels\", fontsize=20)\n","      ax[2].imshow(pred.equal(labels))\n","      ax[2].set_xlabel('X or Y Axis', fontsize=14)\n","      ax[2].set_title(\"wrong predictions\", fontsize=20)\n","\n","plot_image_pred(test2_img[:,:,0], pred2[:,:,0])\n","plot_image_pred(test2_img[:,75,:], pred2[:,75,:])"],"execution_count":null,"outputs":[]}]}