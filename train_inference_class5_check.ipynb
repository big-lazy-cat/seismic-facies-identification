{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_inference_class5.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"26UGd_DJ3ePU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607263434184,"user_tz":-60,"elapsed":14781,"user":{"displayName":"JiangHao Tian","photoUrl":"","userId":"14788170005003873408"}},"outputId":"7b77e413-e8c6-4b5b-db7a-80b206247dca"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')\n","\n","! pip install --upgrade albumentations\n","import albumentations as A\n","\n","from copy import copy\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import gc\n","import tqdm\n","from sklearn.model_selection import StratifiedKFold\n","import cv2\n","\n","import torch\n","torch.backends.cudnn.benchmark = True\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset, Subset\n","\n","!pip install catalyst\n","from catalyst import utils, dl, callbacks\n","SEED = 42\n","utils.set_global_seed(SEED)\n","utils.prepare_cudnn(deterministic=True)\n","\n","!pip install segmentation_models_pytorch\n","import segmentation_models_pytorch as smp"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","Requirement already up-to-date: albumentations in /usr/local/lib/python3.6/dist-packages (0.5.2)\n","Requirement already satisfied, skipping upgrade: imgaug>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from albumentations) (0.4.0)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n","Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations) (3.13)\n","Requirement already satisfied, skipping upgrade: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (4.4.0.46)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.18.5)\n","Requirement already satisfied, skipping upgrade: scikit-image>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (0.16.2)\n","Requirement already satisfied, skipping upgrade: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n","Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (3.2.2)\n","Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (7.0.0)\n","Requirement already satisfied, skipping upgrade: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (2.4.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n","Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations) (4.1.2.30)\n","Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5)\n","Requirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.4.7)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (0.10.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (2.8.1)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations) (1.3.1)\n","Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n","Requirement already satisfied: catalyst in /usr/local/lib/python3.6/dist-packages (20.11)\n","Requirement already satisfied: deprecation in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.1.0)\n","Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.4.1)\n","Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.1.4)\n","Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.3.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.13)\n","Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.41.1)\n","Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.7.0+cu101)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst) (5.5.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.2.2)\n","Requirement already satisfied: GitPython>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.1.11)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.22.2.post1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst) (20.4)\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.1)\n","Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.18.5)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.3.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.10.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.17.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (50.3.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.3.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.33.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.4.2)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (0.35.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (1.7.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (0.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst) (0.16.0)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.8.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (1.0.18)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.3.3)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (2.6.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (2.4.7)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=3.1.1->catalyst) (4.0.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (0.17.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (1.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2.10)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (2.0.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (1.3.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst) (0.6.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst) (0.2.0)\n","Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.1->catalyst) (3.0.4)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (3.4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (3.1.0)\n","Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.6/dist-packages (0.1.2)\n","Requirement already satisfied: timm==0.1.20 in /usr/local/lib/python3.6/dist-packages (from segmentation_models_pytorch) (0.1.20)\n","Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from segmentation_models_pytorch) (0.8.1+cu101)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.6/dist-packages (from segmentation_models_pytorch) (0.7.4)\n","Requirement already satisfied: efficientnet-pytorch==0.6.3 in /usr/local/lib/python3.6/dist-packages (from segmentation_models_pytorch) (0.6.3)\n","Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.6/dist-packages (from timm==0.1.20->segmentation_models_pytorch) (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (1.18.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->segmentation_models_pytorch) (7.0.0)\n","Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (2.5.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.41.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0->timm==0.1.20->segmentation_models_pytorch) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0->timm==0.1.20->segmentation_models_pytorch) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0->timm==0.1.20->segmentation_models_pytorch) (0.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UFoGpVFk4k1K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607263526362,"user_tz":-60,"elapsed":106948,"user":{"displayName":"JiangHao Tian","photoUrl":"","userId":"14788170005003873408"}},"outputId":"097edc7f-514d-4b5c-95b0-45b8ce92f9af"},"source":["competition_path = \"/content/gdrive/My Drive/Seismic Facies Identification/\"\n","data_path = competition_path + \"data/\"\n","train_img = np.load(data_path+'data_train.npz', allow_pickle=True, mmap_mode='r')['data']\n","train_labels = np.load(data_path+'labels_train.npz', allow_pickle=True, mmap_mode='r')['labels']\n","test1_img = np.load(data_path+'data_test_1.npz', allow_pickle=True, mmap_mode='r')['data']\n","test2_img = np.load(data_path+'data_test_2.npz', allow_pickle=True, mmap_mode='r')['data']\n","train_labels -= 1\n","train_labels[:,0,:] = train_labels[:,1,:]\n","\n","pseudo_label = False\n","# add pseudo-label images\n","if pseudo_label:\n","  pseudo_pct = 0.5\n","  submission_file_test1 = competition_path + \"round 1 submissions/prediction20_DLV3Plus_resnext50_32x4d.npz\"\n","  #submission_file_test1 = competition_path + \"submissions/prediction_test1_h.npz\"\n","  submission_file_test2 = competition_path + \"submissions/prediction34_class5_CE_1_5.npz\"\n","  # add images from test1\n","  pred = np.load(submission_file_test1, mmap_mode='r')['prediction']\n","  pred -= 1\n","  pseudo_image_nb_h = int(test1_img.shape[2] * pseudo_pct)\n","  train_img = np.concatenate((train_img, test1_img[:,:,:pseudo_image_nb_h]), axis=2)\n","  train_labels = np.concatenate((train_labels, pred[:,:,:pseudo_image_nb_h]), axis=2)\n","  # add images from test2\n","  pred = np.load(submission_file_test2, mmap_mode='r')['prediction']\n","  pred -= 1\n","  pseudo_image_nb_h = train_img.shape[2]\n","  pseudo_image_nb_v = int(test2_img.shape[1] * pseudo_pct)\n","  train_img = np.concatenate((train_img, test2_img[:,:pseudo_image_nb_v,:pseudo_image_nb_h]), axis=1)\n","  train_labels = np.concatenate((train_labels, pred[:,:pseudo_image_nb_v,:pseudo_image_nb_h]), axis=1)\n","  print(train_img.shape)\n","\n","# merge labels for binary classification\n","binary_class = \"class_012345\" # \"class_4\", \"class_5\", \"class_0123\" or \"class_012345\"\n","if binary_class == \"class_012345\":\n","  classes = 6\n","  weights = [1, 1, 1, 1, 1, 5]\n","elif binary_class == \"class_0123\":\n","  classes = 4\n","  train_labels[train_labels==4] = 1\n","  train_labels[train_labels==5] = 1\n","elif binary_class == \"class_4\":\n","  train_img = train_img[170:618, :, :448] # crop images\n","  train_labels = train_labels[170:618, :, :448] # crop images\n","  classes = 2\n","  train_labels[train_labels==1] = 0\n","  train_labels[train_labels==2] = 0\n","  train_labels[train_labels==3] = 0\n","  train_labels[train_labels==4] = 1\n","  train_labels[train_labels==5] = 0\n","elif binary_class == \"class_5\":\n","  train_img = train_img[92:636, :, :] # crop images\n","  train_labels = train_labels[92:636, :, :] # crop images\n","  classes = 2\n","  weights = [1, 5]\n","  train_labels[train_labels==1] = 0\n","  train_labels[train_labels==2] = 0\n","  train_labels[train_labels==3] = 0\n","  train_labels[train_labels==4] = 0\n","  train_labels[train_labels==5] = 1\n","\n","print(f\"train_img {train_img.shape} train_lables {train_labels.shape} test1_img {test1_img.shape} test2_img {test2_img.shape}\")\n","\n","\"\"\"\n","# normalize values to [0, 1]\n","_min = min(train_img.min(), test1_img.min(), test2_img.min())\n","_max = max(train_img.max(), test1_img.max(), test2_img.max())\n","train_img = (train_img - _min) / (_max - _min)\n","test1_img = (test1_img - _min) / (_max - _min)\n","test2_img = (test2_img - _min) / (_max - _min)\n","\"\"\"\n","# normalize values to max(abs())==1\n","_min = min(train_img.min(), test1_img.min(), test2_img.min())\n","_max = max(train_img.max(), test1_img.max(), test2_img.max())\n","divide = max(-_min, _max)\n","train_img = train_img / divide\n","test1_img = test1_img / divide\n","test2_img = test2_img / divide\n","\n","def calculate_weights(train_labels):\n","  labels = [0, 1, 2, 3, 4, 5]\n","  weights = []\n","  for label in labels:\n","    weights.append(train_labels.size / np.sum(train_labels==label) / len(labels))\n","  return weights\n","\n","#weights = calculate_weights(train_labels)\n","#print(weights)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_img (1006, 782, 590) train_lables (1006, 782, 590) test1_img (1006, 782, 251) test2_img (1006, 334, 841)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBzqMiLlX8l5"},"source":["def train_transform(image, mask):\n","  if binary_class == \"class_012345\" or binary_class == \"class_0123\":\n","    height = 896\n","    width = 256\n","  elif binary_class == \"class_4\":\n","    height = 448\n","    width = 448\n","  elif binary_class == \"class_5\":\n","    height = 544\n","    width = 256\n","  return A.Compose([   \n","    A.ShiftScaleRotate(p=0.7, shift_limit=0, scale_limit=0.15, rotate_limit=25),\n","    #A.Rotate(p=0.8, limit=25, interpolation=cv2.INTER_LINEAR), # cv2.INTER_LINEAR or cv2.INTER_NEAREST\n","    A.RandomCrop(p=1, height=height, width=width),\n","    A.MultiplicativeNoise(p=0.7, multiplier=(0.8, 1.2), per_channel=False, elementwise=False),\n","    #A.OneOf([\n","    #     A.GridDistortion(p=0.8, num_steps=5, distort_limit=0.3, interpolation=cv2.INTER_NEAREST),\n","    #     A.ElasticTransform(p=0.8, alpha=1, sigma=50, alpha_affine=50, interpolation=cv2.INTER_LINEAR),\n","    #    ], p=1),\n","    #A.GaussNoise(p=0.8, var_limit=(10.0, 50.0)), # var_limit to be optimized\n","    A.HorizontalFlip(p=0.5),\n","  ])(image=image, mask=mask)\n","\n","def valid_transform(image, mask):\n","  if binary_class == \"class_012345\" or binary_class == \"class_0123\":\n","    height = 1024\n","    width = 800\n","  elif binary_class == \"class_4\":\n","    height = 448\n","    width = 448\n","  elif binary_class == \"class_5\":\n","    height = 544\n","    width = 800\n","  return A.Compose([\n","    A.PadIfNeeded(p=1, min_height=height, min_width=width), # border_mode=4 reflect_101 \n","  ])(image=image, mask=mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9F6x-l3CdHX"},"source":["class SeismicFaciesDataset(Dataset):\n","  def __init__(self, img, labels, train=True, both_axis=True, channels=3):\n","    self.img = img\n","    self.labels = labels\n","    self.train = train\n","    self.both_axis = both_axis\n","    self.channels = channels\n","    self.side_channels = int((channels - 1) / 2)\n","    self.xaxis = self.img.shape[1]\n","    self.yaxis = self.img.shape[2]\n","    self.ximages = self.xaxis - self.side_channels * 2\n","    self.yimages = self.yaxis - self.side_channels * 2\n","\n","  def __len__(self):\n","    if self.both_axis:\n","      return self.ximages + self.yimages\n","    else:\n","      return self.yimages\n","\n","  def __getitem__(self, idx):\n","    if idx < self.yimages:\n","      image, mask = self.img[:, :, idx:idx+self.channels], self.labels[:, :, idx+self.side_channels]\n","    else:\n","      idx = idx - self.yimages\n","      image, mask = self.img[:, idx:idx+self.channels], self.labels[:, idx+self.side_channels]\n","      image = np.moveaxis(image, 1, 2)\n","\n","    if self.train:\n","      augmented = train_transform(image, mask)\n","    else:\n","      augmented = valid_transform(image, mask)\n","    image, mask = augmented['image'], augmented['mask']\n","        \n","    return [np.moveaxis(image, 2, 0), np.expand_dims(mask, 0)]\n","\n","\n","class SeismicFaciesTestset(Dataset):\n","  def __init__(self, img, batch_axis=2, channels=3): # batch_axis = 1 (x_axis) or 2 (y_axis)\n","    self.img = img\n","    self.batch_axis = batch_axis\n","    self.channels = channels\n","    self.side_channels = int((channels - 1) / 2)\n","    self.image_nb = self.img.shape[self.batch_axis]\n","\n","  def __len__(self):\n","    return self.image_nb\n","\n","  def __getitem__(self, idx):\n","    if idx < self.side_channels:\n","      idx = self.side_channels\n","    \n","    if idx > self.image_nb-self.side_channels-1:\n","      idx = self.image_nb-self.side_channels-1\n","    if self.batch_axis == 2:\n","      image = self.img[:, :, idx-self.side_channels:idx+self.side_channels+1]\n","    else:\n","      image = self.img[:, idx-self.side_channels:idx+self.side_channels+1, :]\n","      image = np.moveaxis(image, 1, 2)\n","\n","    #image = A.PadIfNeeded(p=1, min_height=1024, min_width=800)(image=image)[\"image\"]\n","    bboxes = [[0, 0, image.shape[1], image.shape[0], \"original_image\"]] # width and then height\n","    augmented = A.Compose([\n","          A.PadIfNeeded(p=1, min_height=1024, min_width=1024),\n","          ], bbox_params=A.BboxParams(format='coco'))(image=image, bboxes=bboxes)\n","    image, self.bboxes = augmented[\"image\"], augmented[\"bboxes\"]\n","    return [np.moveaxis(image, 2, 0)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TfI21QxGqPlf"},"source":["class GDiceLoss(torch.nn.Module):\n","    def __init__(self, apply_nonlin=None, smooth=1e-5):\n","        \"\"\"\n","        Generalized Dice;\n","        Copy from: https://github.com/LIVIAETS/surface-loss/blob/108bd9892adca476e6cdf424124bc6268707498e/losses.py#L29\n","        paper: https://arxiv.org/pdf/1707.03237.pdf\n","        tf code: https://github.com/NifTK/NiftyNet/blob/dev/niftynet/layer/loss_segmentation.py#L279\n","        \"\"\"\n","        super(GDiceLoss, self).__init__()\n","\n","        self.apply_nonlin = apply_nonlin\n","        self.smooth = smooth\n","\n","    def forward(self, net_output, gt):\n","        shp_x = net_output.shape # (batch size,class_num,x,y,z)\n","        shp_y = gt.shape # (batch size,1,x,y,z)\n","        # one hot code for gt\n","        with torch.no_grad():\n","            if len(shp_x) != len(shp_y):\n","                gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n","\n","            if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n","                # if this is the case then gt is probably already a one hot encoding\n","                y_onehot = gt\n","            else:\n","                gt = gt.long()\n","                y_onehot = torch.zeros(shp_x)\n","                if net_output.device.type == \"cuda\":\n","                    y_onehot = y_onehot.cuda(net_output.device.index)\n","                y_onehot.scatter_(1, gt, 1)\n","\n","\n","        if self.apply_nonlin is not None:\n","            net_output = self.apply_nonlin(net_output)\n","    \n","        # copy from https://github.com/LIVIAETS/surface-loss/blob/108bd9892adca476e6cdf424124bc6268707498e/losses.py#L29\n","        w: torch.Tensor = 1 / (torch.einsum(\"bcxy->bc\", y_onehot).type(torch.float32) + 1e-10)**2\n","        intersection: torch.Tensor = w * torch.einsum(\"bcxy, bcxy->bc\", net_output, y_onehot)\n","        union: torch.Tensor = w * (torch.einsum(\"bcxy->bc\", net_output) + torch.einsum(\"bcxy->bc\", y_onehot))\n","        divided: torch.Tensor =  - 2 * (torch.einsum(\"bc->b\", intersection) + self.smooth) / (torch.einsum(\"bc->b\", union) + self.smooth)\n","        gdc = divided.mean()\n","\n","        return gdc\n","\n","\n","def flatten(tensor):\n","    \"\"\"Flattens a given tensor such that the channel axis is first.\n","    The shapes are transformed as follows:\n","       (N, C, D, H, W) -> (C, N * D * H * W)\n","    \"\"\"\n","    C = tensor.size(1)\n","    # new axis order\n","    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n","    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n","    transposed = tensor.permute(axis_order).contiguous()\n","    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n","    return transposed.view(C, -1)\n","\n","class GDiceLossV2(torch.nn.Module):\n","    def __init__(self, apply_nonlin=None, smooth=1e-5):\n","        \"\"\"\n","        Generalized Dice;\n","        Copy from: https://github.com/wolny/pytorch-3dunet/blob/6e5a24b6438f8c631289c10638a17dea14d42051/unet3d/losses.py#L75\n","        paper: https://arxiv.org/pdf/1707.03237.pdf\n","        tf code: https://github.com/NifTK/NiftyNet/blob/dev/niftynet/layer/loss_segmentation.py#L279\n","        \"\"\"\n","        super(GDiceLossV2, self).__init__()\n","\n","        self.apply_nonlin = apply_nonlin\n","        self.smooth = smooth\n","\n","    def forward(self, net_output, gt):\n","        shp_x = net_output.shape # (batch size,class_num,x,y,z)\n","        shp_y = gt.shape # (batch size,1,x,y,z)\n","        # one hot code for gt\n","        with torch.no_grad():\n","            if len(shp_x) != len(shp_y):\n","                gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n","\n","            if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n","                # if this is the case then gt is probably already a one hot encoding\n","                y_onehot = gt\n","            else:\n","                gt = gt.long()\n","                y_onehot = torch.zeros(shp_x)\n","                if net_output.device.type == \"cuda\":\n","                    y_onehot = y_onehot.cuda(net_output.device.index)\n","                y_onehot.scatter_(1, gt, 1)\n","\n","\n","        if self.apply_nonlin is not None:\n","            net_output = self.apply_nonlin(net_output)\n","\n","        input = flatten(net_output)\n","        target = flatten(y_onehot)\n","        target = target.float()\n","        target_sum = target.sum(-1)\n","        #weights_base = [1.539948, 0.4490113, 6.48968674, 0.50709277, 11.38007304, 1.09947775]\n","          # weights_base is calculated by : np.array(calculate_weights(train_labels[:,-50:,:]))\n","        #weights = [1.539948, 0.4490113, 6.48968674, 0.50709277] # (for class0123)\n","        #weights = [1.539948, 0.4490113, 6.48968674, 0.50709277, 113.8007304, 1.09947775] # weights_base*[1,1,1,1,10,1] (for class4)\n","        weights = [1.539948, 0.4490113, 6.48968674, 0.50709277, 11.38007304, 5.49738875] # weights_base**[1,1,1,1,1,5] (for class5)\n","        class_weights = torch.tensor(weights).cuda(net_output.device.index)\n","\n","        intersect = (input * target).sum(-1) * class_weights\n","        intersect = intersect.sum()\n","\n","        denominator = ((input + target).sum(-1) * class_weights).sum()\n","\n","        return  - 2. * intersect / denominator.clamp(min=self.smooth)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzvxPwgSvSkq"},"source":["import catalyst\n","import sklearn\n","\n","# catalyst pipeline\n","channels = 1\n","batch_size = 8\n","valid_batch_size = 4\n","\n","class CustomRunner(dl.Runner):\n","\n","  def predict_batch(self, batch):\n","      # model inference step\n","      return self.model(batch[0].to(self.device))\n","\n","  def _handle_batch(self, batch):\n","      # model train/valid step\n","      x, y = batch\n","      y_hat = self.model(x)\n","      \n","      loss = self.criterion[\"CE\"](y_hat, torch.squeeze(y.long()))*0.3 + self.criterion[\"GDice\"](y_hat, torch.squeeze(y.long()))*0.7\n","      y_hat_reshaped = y_hat.permute(0, 2, 3, 1).reshape(-1, classes)\n","      y_reshaped = y.permute(0, 2, 3, 1).reshape(-1, 1)\n","      #f1_score = sklearn.metrics.f1_score(y_reshaped.cpu().detach().numpy(), y_hat_reshaped.cpu().detach().numpy().argmax(axis=1), average='macro')\n","      #accuracy01, accuracy02 = catalyst.metrics.accuracy(y_hat_reshaped, y_reshaped, topk=(1, 2))\n","      [accuracy01] = catalyst.metrics.accuracy(y_hat_reshaped, y_reshaped)\n","      f1_score = catalyst.metrics.f1_score(torch.argmax(y_hat_reshaped, dim=1, keepdims=True), y_reshaped, num_classes=classes)\n","\n","      self.batch_metrics.update(\n","          {\"loss\": loss, \"accuracy_01\": accuracy01, \"f1_score\": f1_score[5]} # \"accuracy_2\": accuracy02, \"f1_score\": f1_score\n","      )\n","\n","      if self.is_train_loader:\n","          loss.backward()\n","          self.optimizer.step()\n","          self.optimizer.zero_grad()\n","\n","#model = smp.Unet(encoder_name=\"efficientnet-b3\", in_channels=channels, classes=classes, activation=\"softmax\", decoder_attention_type=\"scse\", encoder_weights='imagenet')\n","model = smp.DeepLabV3Plus(encoder_name=\"efficientnet-b3\", in_channels=channels, classes=classes, activation=\"softmax\", encoder_weights='imagenet')\n","#model = smp.DeepLabV3Plus(encoder_name=\"resnext50_32x4d\", in_channels=channels, classes=classes, activation=\"softmax\", encoder_weights='imagenet')\n","#model = smp.DeepLabV3Plus(encoder_name=\"se_resnext101_32x4d\", in_channels=channels, classes=classes, activation=\"softmax\", encoder_weights='imagenet')\n","#model = smp.DeepLabV3Plus(encoder_name=\"inception_resnet_v2\", in_channels=channels, classes=classes, activation=\"softmax\", encoder_weights='imagenet')\n","#model = smp.Unet(encoder_name=\"efficientnet-b3\", in_channels=channels, classes=classes, activation=\"softmax\", decoder_attention_type=\"scse\", encoder_weights='imagenet')\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","#criterion = catalyst.contrib.nn.LovaszLossMultiClass()\n","criterion_CE = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(weights).cuda())\n","criterion_GDice = GDiceLossV2()\n","#criterion = catalyst.contrib.nn.DiceLoss(activation=None)\n","#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.1, patience=2)\n","es_callback = callbacks.early_stop.EarlyStoppingCallback(patience=5, metric='loss', minimize=True, min_delta=1e-6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"veoH4wujyCkk"},"source":["# train\n","valid_ratio = 0.1\n","\n","dataset = SeismicFaciesDataset(train_img, train_labels, channels=channels)\n","nb_valid_xaxis = int(dataset.xaxis * valid_ratio)\n","nb_valid_yaxis = int(dataset.yaxis * valid_ratio)\n","# split\n","#train_index = list(range(nb_valid_yaxis, dataset.yaxis)) + list(range(dataset.yaxis + nb_valid_xaxis, dataset.__len__()))\n","#valid_index = list(range(0, nb_valid_yaxis)) + list(range(dataset.yaxis, dataset.yaxis + nb_valid_xaxis))\n","# split (train set = whole data; valid set = near to test set)\n","#train_index = list(range(0, dataset.__len__()))\n","#valid_index = list(range(dataset.__len__() - nb_valid_xaxis, dataset.__len__()))\n","# split (train set = whole data; valid set = equally spaced images)\n","train_index = list(range(0, dataset.__len__()))\n","valid_index = list(range(0, dataset.__len__(), int(1/valid_ratio)))\n","\n","train_dataset, valid_dataset = Subset(dataset, train_index), Subset(copy(dataset), valid_index)\n","valid_dataset.dataset.train = False\n","\n","loaders = {\n","  \"train\": DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True, drop_last=True),\n","  \"valid\": DataLoader(valid_dataset, batch_size=valid_batch_size, num_workers=0, shuffle=False, drop_last=False),\n","}\n","\n","#checkpoint = utils.load_checkpoint(f'{competition_path}/logs/checkpoints/best_class5_04.pth')\n","#utils.unpack_checkpoint(checkpoint, model=model)\n","runner = CustomRunner()\n","# model training\n","runner.train(\n","  model=model,\n","  optimizer=optimizer,\n","  criterion={\"CE\": criterion_CE, \"GDice\": criterion_GDice}, \n","  #scheduler=scheduler,\n","  loaders=loaders,\n","  logdir=competition_path+\"logs/\",\n","  callbacks=[es_callback],\n","  num_epochs=20,\n","  verbose=True,\n","  load_best_on_end=True,\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tmqYtY9R6v-G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607263663066,"user_tz":-60,"elapsed":238597,"user":{"displayName":"JiangHao Tian","photoUrl":"","userId":"14788170005003873408"}},"outputId":"6376eed9-6003-4797-b1a8-4ed2a940d2c2"},"source":["def inference(img, batch_axis=1):\n","  predict_from_checkpoint = True\n","  TTA = False\n","\n","  testset = SeismicFaciesTestset(img, batch_axis=batch_axis, channels=channels)\n","  testloader = DataLoader(testset, batch_size=1, num_workers=0, shuffle=False)\n","\n","  if predict_from_checkpoint:\n","    checkpoint = utils.load_checkpoint(f'{competition_path}/logs/checkpoints/class5_04_train.19.pth')\n","    utils.unpack_checkpoint(checkpoint, model=model)\n","    runner = CustomRunner(model=model)\n","    print(\"Checkpoint loaded.\")\n","\n","  if TTA:\n","    !pip install ttach\n","    import ttach as tta\n","    transforms = tta.Compose([\n","          tta.HorizontalFlip(),\n","          #tta.Multiply([0.95, 1, 1.05]),\n","          #tta.Add([-0.05, 0, 0.05]),\n","          #tta.Scale([1, 2]),\n","      ])\n","    tta_model = tta.SegmentationTTAWrapper(model, transforms)\n","    runner = CustomRunner(model=tta_model)\n","    \n","  pred = []\n","  for pred_batch in tqdm.tqdm(runner.predict_loader(loader=testloader)):\n","    bboxes = testloader.dataset.bboxes[0]\n","    pred_batch_np = pred_batch.cpu().numpy().argmax(axis=1)\n","    pred_batch_np = pred_batch_np[:, int(bboxes[1]):int(bboxes[1]+bboxes[3]), int(bboxes[0]):int(bboxes[0]+bboxes[2])]\n","    pred.append(pred_batch_np.copy())\n","  pred = np.concatenate(pred, axis=0)\n","  if batch_axis==1:\n","    pred = pred.transpose((1, 0, 2))\n","  else:\n","    pred = pred.transpose((1, 2, 0))\n","\n","  return pred\n","\n","del train_img, test1_img\n","gc.collect()\n","#pred1 = inference(test1_img, batch_axis=2)\n","pred2 = inference(test2_img, batch_axis=1) # vertical images"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r0it [00:00, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Checkpoint loaded.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/segmentation_models_pytorch/base/modules.py:102: UserWarning:\n","\n","Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","\n","334it [02:02,  2.74it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"impcX8uFJ5QM","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1607263668188,"user_tz":-60,"elapsed":233409,"user":{"displayName":"JiangHao Tian","photoUrl":"","userId":"14788170005003873408"}},"outputId":"f4ce625d-9405-4958-ae14-9d7b874100b1"},"source":["from google.colab import files\n","\n","def download_submission(pred, submission_file):\n","  np.savez_compressed(\n","      submission_file,\n","      prediction=pred.astype(train_labels.dtype) + 1\n","  )\n","  files.download(submission_file)\n","\n","# submission for testset 1\n","submission_file = competition_path+'submissions/prediction_test1.npz'\n","#download_submission(pred1, submission_file)\n","# submission for testset 2\n","submission_file = competition_path+'binary_predictions/class5_04_CE0.3_GDice0.7_w5_train19.npz'\n","download_submission(pred2, submission_file)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_5f9245d3-28f2-4be6-9ebb-ace2b7cdf732\", \"prediction_test2.npz\", 3031726)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9esoIPK7YHxD"},"source":["# plot image & predictions\n","def plot_image_pred(image, pred=None, labels=None):\n","\n","  # plot image & labels\n","  fig, ax = plt.subplots(1,3, sharey=True)\n","  fig.set_size_inches(20, 8)\n","  fig.suptitle(\"2D slice of the 3D seismic data volume\", fontsize=20)\n","  ax[0].imshow(image, cmap='terrain')\n","  ax[0].set_xlabel('X or Y Axis', fontsize=14)\n","  ax[0].set_ylabel('Z Axis: Top - Bottom', fontsize=14)\n","  ax[0].set_title(\"image\", fontsize=20)\n","  if labels is not None:\n","    print(np.unique(labels))\n","    ax[1].imshow(labels)\n","    ax[1].set_xlabel('X or Y Axis', fontsize=14)\n","    ax[1].set_title(\"labels\", fontsize=20)\n","    ax[2].imshow(image, cmap='terrain')\n","    ax[2].imshow(labels, alpha=0.4, cmap='twilight')\n","    ax[2].set_xlabel('X or Y Axis', fontsize=14)\n","    ax[2].set_title(\"image + labels\", fontsize=20)\n","\n","  # plot pred & labels\n","  if pred is not None:\n","    fig, ax = plt.subplots(1,3, sharey=True)\n","    fig.set_size_inches(20, 8)\n","    fig.suptitle(\"Predictions & labels\", fontsize=20)\n","    ax[0].imshow(pred)\n","    ax[0].set_xlabel('X or Y Axis', fontsize=14)\n","    ax[0].set_title(\"predictions\", fontsize=20)\n","    if labels is not None:\n","      ax[1].imshow(labels)\n","      ax[1].set_xlabel('X or Y Axis', fontsize=14)\n","      ax[1].set_title(\"labels\", fontsize=20)\n","      ax[2].imshow(pred.equal(labels))\n","      ax[2].set_xlabel('X or Y Axis', fontsize=14)\n","      ax[2].set_title(\"wrong predictions\", fontsize=20)\n","\n","plot_image_pred(test2_img[:,:,810], pred2[:,:,810])\n","plot_image_pred(test2_img[:,140,:], pred2[:,140,:])"],"execution_count":null,"outputs":[]}]}